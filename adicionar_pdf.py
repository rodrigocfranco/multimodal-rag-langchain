#!/usr/bin/env python3
"""
Adicionar PDF ao Knowledge Base
Sistema √∫nico e simples com metadados otimizados
"""

import os
import sys
from dotenv import load_dotenv
import time
from document_manager import generate_pdf_id, check_duplicate

load_dotenv()

if len(sys.argv) < 2:
    print("Uso: python adicionar_pdf.py arquivo.pdf")
    print("   ou: python adicionar_pdf.py content/arquivo.pdf")
    exit(1)

# Aceitar tanto "arquivo.pdf" quanto "content/arquivo.pdf"
input_path = sys.argv[1]

if os.path.exists(input_path):
    # Caminho completo fornecido
    file_path = input_path
    pdf_filename = os.path.basename(input_path)
elif os.path.exists(f"./content/{input_path}"):
    # S√≥ nome do arquivo fornecido
    file_path = f"./content/{input_path}"
    pdf_filename = input_path
else:
    print(f"‚ùå PDF n√£o encontrado: {input_path}")
    print(f"   Tentou tamb√©m: ./content/{input_path}")
    exit(1)

print(f"üìÑ Processando: {pdf_filename}")
print("‚è≥ Aguarde 5-10 minutos...\n")

# Vectorstore unificado - Railway Volume
persist_directory = os.getenv("PERSIST_DIR", "./knowledge")

# ===========================================================================
# GERAR PDF_ID E VERIFICAR DUPLICATA
# ===========================================================================
print("üîç Gerando ID do documento...")
pdf_id = generate_pdf_id(file_path)
file_size = os.path.getsize(file_path)
uploaded_at = time.strftime("%Y-%m-%d %H:%M:%S")

print(f"   PDF_ID: {pdf_id[:16]}...")
print(f"   Tamanho: {file_size / 1024 / 1024:.2f} MB")

# Verificar se PDF j√° foi processado
existing_doc = check_duplicate(file_path, persist_directory)
if existing_doc:
    print(f"\n‚ö†Ô∏è  Este PDF j√° foi processado!")
    print(f"   Adicionado em: {existing_doc.get('uploaded_at', 'desconhecido')}")
    print(f"   Chunks: {existing_doc.get('stats', {}).get('total_chunks', 0)}")

    if os.getenv("AUTO_REPROCESS") != "true":
        choice = input("\nReprocessar? (s/N): ")
        if choice.lower() != 's':
            print("‚ùå Processamento cancelado.")
            exit(0)
        print("\nüîÑ Reprocessando documento...\n")
    else:
        print("\nüîÑ AUTO_REPROCESS=true, reprocessando automaticamente...\n")
else:
    print("‚úÖ Documento novo, prosseguindo...\n")

# ===========================================================================
# EXTRAIR E PROCESSAR PDF
# ===========================================================================
from unstructured.partition.pdf import partition_pdf

# Permite alternar a estrat√©gia via vari√°vel de ambiente e faz fallback autom√°tico
strategy_env = os.getenv("UNSTRUCTURED_STRATEGY", "hi_res").strip().lower()

def run_partition(strategy: str):
    return partition_pdf(
        filename=file_path,
        infer_table_structure=True,
        strategy=strategy,
        extract_image_block_types=["Image", "Table"],
        extract_image_block_to_payload=True,
        languages=["por"],  # ‚úÖ For√ßa OCR em portugu√™s

        # ‚úÖ CHUNKING OTIMIZADO PARA DOCUMENTOS M√âDICOS
        # NOTA IMPORTANTE: Tabelas s√£o SEMPRE preservadas inteiras (isoladas)
        # tanto em by_title quanto em basic - ver documenta√ß√£o Unstructured
        chunking_strategy="by_title",

        # Hard maximum: ~2500 tokens - chunks grandes preservam contexto completo
        max_characters=10000,

        # Agrupa elementos pequenos (<4000 chars) no mesmo chunk
        # Combina m√∫ltiplos par√°grafos relacionados da mesma se√ß√£o
        combine_text_under_n_chars=4000,

        # Soft maximum: for√ßa quebra em 6000 chars (~1500 tokens)
        # Balanceia contexto amplo com efici√™ncia de retrieval
        new_after_n_chars=6000,
    )

try:
    # Tenta com a estrat√©gia definida (padr√£o hi_res)
    chunks = run_partition(strategy_env)
    strategy_used = strategy_env
except Exception as e:
    # Se falhar por falta de libGL/cv2, faz fallback para 'fast'
    if "libGL.so.1" in str(e) or "cv2" in str(e) or "detectron2onnx" in str(e):
        print("‚ö†Ô∏è  Falha em hi_res (prov√°vel falta de libGL). Usando strategy='fast'.")
        chunks = run_partition("fast")
        strategy_used = "fast"
    else:
        raise

print(f"1Ô∏è‚É£  Extra√≠do: {len(chunks)} elementos (estrat√©gia: {strategy_used})")

# Separar elementos
# Com chunking by_title, Unstructured retorna:
# - CompositeElement: textos agrupados por se√ß√£o
# - Table: tabelas isoladas (sempre preservadas inteiras)
tables = []
texts = []

for chunk in chunks:
    chunk_type = str(type(chunk))

    if "Table" in chunk_type:
        tables.append(chunk)

    if "CompositeElement" in chunk_type:
        texts.append(chunk)

# ===========================================================================
# FUN√á√ïES DE EXTRA√á√ÉO DE METADATA M√âDICO
# ===========================================================================
def extract_section_heading(text_element):
    """
    Extrai section heading de elementos de texto
    Detecta se√ß√µes m√©dicas comuns em artigos cient√≠ficos

    Args:
        text_element: Elemento de texto do Unstructured

    Returns:
        str: Nome da se√ß√£o (Title case) ou None se n√£o detectado
    """
    # Verificar se elemento tem metadata
    if not hasattr(text_element, 'metadata'):
        return None

    # Unstructured detecta categorias automaticamente
    if hasattr(text_element.metadata, 'category'):
        cat = text_element.metadata.category

        # Se for Title, tentar identificar qual se√ß√£o
        if cat == 'Title':
            text = text_element.text if hasattr(text_element, 'text') else str(text_element)
            text_lower = text.lower().strip()

            # Se√ß√µes m√©dicas/cient√≠ficas comuns (em portugu√™s e ingl√™s)
            medical_sections = {
                # Portugu√™s
                'resumo': 'Resumo',
                'abstract': 'Abstract',
                'introdu√ß√£o': 'Introdu√ß√£o',
                'introduction': 'Introduction',
                'contexto': 'Contexto',
                'background': 'Background',
                'objetivos': 'Objetivos',
                'objectives': 'Objectives',
                'm√©todos': 'M√©todos',
                'metodologia': 'Metodologia',
                'methods': 'Methods',
                'methodology': 'Methodology',
                'materiais e m√©todos': 'Materiais e M√©todos',
                'materials and methods': 'Materials and Methods',
                'resultados': 'Resultados',
                'results': 'Results',
                'discuss√£o': 'Discuss√£o',
                'discussion': 'Discussion',
                'conclus√£o': 'Conclus√£o',
                'conclus√µes': 'Conclus√£o',  # Mapeia para singular
                'conclusion': 'Conclusion',
                'conclusions': 'Conclusion',  # Mapeia para singular
                'refer√™ncias': 'Refer√™ncias',
                'references': 'References',
                'bibliografia': 'Bibliografia',
                'agradecimentos': 'Agradecimentos',
                'acknowledgments': 'Acknowledgments',
                'acknowledgements': 'Acknowledgements',
                # Se√ß√µes m√©dicas espec√≠ficas
                'relato de caso': 'Relato de Caso',
                'case report': 'Case Report',
                'apresenta√ß√£o do caso': 'Apresenta√ß√£o do Caso',
                'case presentation': 'Case Presentation',
                'achados cl√≠nicos': 'Achados Cl√≠nicos',
                'clinical findings': 'Clinical Findings',
                'diagn√≥stico': 'Diagn√≥stico',
                'diagnosis': 'Diagnosis',
                'diagn√≥stico diferencial': 'Diagn√≥stico Diferencial',
                'differential diagnosis': 'Differential Diagnosis',
                'tratamento': 'Tratamento',
                'treatment': 'Treatment',
                'terap√™utica': 'Terap√™utica',
                'therapeutics': 'Therapeutics',
                'manejo': 'Manejo',
                'management': 'Management',
                'evolu√ß√£o': 'Evolu√ß√£o',
                'outcome': 'Outcome',
                'desfecho': 'Desfecho',
                'follow-up': 'Follow-up',
                'acompanhamento': 'Acompanhamento',
                'complica√ß√µes': 'Complica√ß√µes',
                'complications': 'Complications',
                'efeitos adversos': 'Efeitos Adversos',
                'adverse effects': 'Adverse Effects',
            }

            # Procurar match exato ou por substring
            for key, value in medical_sections.items():
                if key in text_lower:
                    return value

    return None


def infer_document_type(filename):
    """
    Infere tipo de documento m√©dico pelo nome do arquivo

    Args:
        filename: Nome do arquivo PDF

    Returns:
        str: Tipo do documento (lowercase com underscore)
    """
    filename_lower = filename.lower()

    # Artigos de revis√£o
    if any(word in filename_lower for word in ['artigo de revis√£o', 'review article', 'review -', '- review']):
        return 'review_article'

    # Guidelines / Diretrizes
    if any(word in filename_lower for word in ['guideline', 'diretriz', 'consenso', 'consensus', 'recomenda√ß√µes']):
        return 'clinical_guideline'

    # Relatos de caso
    if any(word in filename_lower for word in ['case report', 'relato de caso', 'case series']):
        return 'case_report'

    # Ensaios cl√≠nicos / RCTs
    if any(word in filename_lower for word in ['rct', 'trial', 'ensaio cl√≠nico', 'clinical trial', 'randomized']):
        return 'clinical_trial'

    # Meta-an√°lises
    if any(word in filename_lower for word in ['meta-analysis', 'metan√°lise', 'meta-an√°lise', 'systematic review', 'revis√£o sistem√°tica']):
        return 'meta_analysis'

    # Estudos de coorte
    if any(word in filename_lower for word in ['cohort', 'coorte', 'prospective study', 'estudo prospectivo']):
        return 'cohort_study'

    # Estudos observacionais
    if any(word in filename_lower for word in ['observational', 'observacional', 'cross-sectional', 'transversal']):
        return 'observational_study'

    # Artigos originais / pesquisa
    if any(word in filename_lower for word in ['original article', 'artigo original', 'research article', 'research paper']):
        return 'original_research'

    # Editoriais / Coment√°rios
    if any(word in filename_lower for word in ['editorial', 'commentary', 'coment√°rio', 'perspective']):
        return 'editorial'

    # Default: artigo m√©dico gen√©rico
    return 'medical_article'


# Extrair imagens base64 dos CompositeElements
def get_images_base64(chunks):
    """
    Extrai imagens de dentro dos CompositeElements.
    Imagens v√™m em metadata.orig_elements
    """
    images_b64 = []
    seen_hashes = set()  # Deduplica√ß√£o
    filtered_count = 0

    # Filtro: imagens muito pequenas geralmente s√£o √≠cones/decora√ß√£o
    MIN_IMAGE_SIZE_KB = float(os.getenv("MIN_IMAGE_SIZE_KB", "5"))

    for chunk in chunks:
        if "CompositeElement" in str(type(chunk)):
            if hasattr(chunk, 'metadata') and hasattr(chunk.metadata, 'orig_elements'):
                chunk_els = chunk.metadata.orig_elements
                if chunk_els:
                    for el in chunk_els:
                        if "Image" in str(type(el)):
                            if hasattr(el, 'metadata') and hasattr(el.metadata, 'image_base64'):
                                img = el.metadata.image_base64
                                if img and len(img) > 100:
                                    size_kb = len(img) / 1024

                                    # Filtrar imagens muito pequenas
                                    if size_kb >= MIN_IMAGE_SIZE_KB:
                                        # Deduplicar por hash
                                        img_hash = hash(img[:1000])
                                        if img_hash not in seen_hashes:
                                            seen_hashes.add(img_hash)
                                            images_b64.append(img)
                                    else:
                                        filtered_count += 1

    return images_b64, filtered_count

images, filtered_count = get_images_base64(chunks)
duplicate_count = 0  # J√° deduplicado na fun√ß√£o

# Modo debug: mostrar detalhes das imagens
if os.getenv("DEBUG_IMAGES"):
    print("\n   [DEBUG] Detalhes das imagens extra√≠das:")
    for i, img in enumerate(images):
        size_kb = len(img) / 1024
        print(f"     Imagem {i+1}: {size_kb:.1f} KB")
    print(f"   [DEBUG] Filtradas (muito pequenas): {filtered_count}")
    print(f"   [DEBUG] Duplicatas removidas: {duplicate_count}")

print(f"   ‚úì {len(texts)} textos, {len(tables)} tabelas, {len(images)} imagens")
if filtered_count > 0:
    print(f"      (filtradas: {filtered_count} imagens pequenas <5KB)")
print()

# ===========================================================================
# GERAR RESUMOS COM IA
# ===========================================================================
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

print("2Ô∏è‚É£  Gerando resumos...")

# Upgrade: Llama ‚Üí GPT-4o-mini para resumos mais precisos (+40% qualidade)
model = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)  # Era Llama-8b
prompt = ChatPromptTemplate.from_template(
    "Summarize concisely: {element}"
)
summarize = {"element": lambda x: x} | prompt | model | StrOutputParser()

# Textos
text_summaries = []
for i, text in enumerate(texts):
    try:
        content = text.text if hasattr(text, 'text') else str(text)
        text_summaries.append(summarize.invoke(content))
        print(f"   Textos: {i+1}/{len(texts)}", end="\r")
        time.sleep(0.5)
    except:
        text_summaries.append(content[:500])
print(f"   ‚úì {len(text_summaries)} textos")

# Tabelas
table_summaries = []
if tables:
    for i, table in enumerate(tables):
        try:
            content = table.metadata.text_as_html if hasattr(table, 'metadata') and hasattr(table.metadata, 'text_as_html') else table.text if hasattr(table, 'text') else str(table)
            table_summaries.append(summarize.invoke(content))
            print(f"   Tabelas: {i+1}/{len(tables)}", end="\r")
            time.sleep(0.5)
        except:
            table_summaries.append(content[:500])
    print(f"   ‚úì {len(table_summaries)} tabelas")

# Imagens
image_summaries = []
if images:
    import base64
    
    prompt_img = ChatPromptTemplate.from_messages([
        ("user", [
            {"type": "text", "text": "Describe this image:"},
            {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,{image}"}},
        ])
    ])
    chain_img = prompt_img | ChatOpenAI(model="gpt-4o-mini") | StrOutputParser()
    
    for i, img in enumerate(images):
        try:
            size_kb = len(img) / 1024
            if 1 < size_kb < 20000:
                base64.b64decode(img[:100])
                print(f"   Imagens: {i+1}/{len(images)} ({size_kb:.1f}KB)...", end="\r")
                image_summaries.append(chain_img.invoke(img))
                time.sleep(0.8)
            else:
                print(f"   Imagens: {i+1}/{len(images)} (ignorada: {size_kb:.1f}KB)", end="\r")
                image_summaries.append(f"Imagem {i+1}")
        except Exception as e:
            print(f"   Imagens: {i+1}/{len(images)} ERRO: {str(e)[:100]}", end="\r")
            image_summaries.append(f"Imagem {i+1} (erro: {str(e)[:50]})")
    print(f"   ‚úì {len(image_summaries)} imagens processadas\n")

# ===========================================================================
# ADICIONAR AO KNOWLEDGE BASE
# ===========================================================================
print("3Ô∏è‚É£  Adicionando ao knowledge base...")

import uuid
from langchain_chroma import Chroma
from langchain.storage import InMemoryStore
from langchain.schema.document import Document
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers.multi_vector import MultiVectorRetriever
import pickle

os.makedirs(persist_directory, exist_ok=True)

vectorstore = Chroma(
    collection_name="knowledge_base",
    embedding_function=OpenAIEmbeddings(model="text-embedding-3-large"),  # Upgrade para melhor sem√¢ntica
    persist_directory=persist_directory
)

docstore_path = f"{persist_directory}/docstore.pkl"
store = InMemoryStore()
if os.path.exists(docstore_path):
    with open(docstore_path, 'rb') as f:
        store.store = pickle.load(f)

retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=store,
    id_key="doc_id",
)

# Inferir document_type uma vez (baseado no filename)
document_type = infer_document_type(pdf_filename)
print(f"   Tipo detectado: {document_type}")

# Adicionar com metadados
chunk_ids = []  # Para tracking
for i, summary in enumerate(text_summaries):
    doc_id = str(uuid.uuid4())
    chunk_ids.append(doc_id)

    # Extrair page_number se dispon√≠vel
    page_num = None
    if hasattr(texts[i], 'metadata') and hasattr(texts[i].metadata, 'page_number'):
        page_num = texts[i].metadata.page_number

    # Extrair section heading (contexto m√©dico)
    section = extract_section_heading(texts[i])

    # ‚úÖ NOVO: Incluir texto original + resumo para melhor retrieval
    original_text = texts[i].text if hasattr(texts[i], 'text') else str(texts[i])
    combined_content = f"{summary}\n\n[TEXTO ORIGINAL]\n{original_text}"

    doc = Document(
        page_content=combined_content,  # ‚úÖ TEXTO COMPLETO + RESUMO
        metadata={
            "doc_id": doc_id,
            "pdf_id": pdf_id,  # ‚úÖ ID do PDF
            "source": pdf_filename,
            "type": "text",
            "index": i,
            "page_number": page_num,
            "uploaded_at": uploaded_at,
            "section": section,              # ‚úÖ NOVO: Se√ß√£o do documento
            "document_type": document_type,  # ‚úÖ NOVO: Tipo de documento
            "summary": summary,               # ‚úÖ NOVO: Guardar resumo separado
        }
    )
    
    # Adicionar source ao documento original
    original = texts[i]
    
    # Criar metadata dict se n√£o existir
    if not hasattr(original, 'metadata'):
        # Criar um objeto simples com metadata
        class DocWithMetadata:
            def __init__(self, text, metadata):
                self.text = text
                self.metadata = metadata
        original = DocWithMetadata(original.text if hasattr(original, 'text') else str(original), {'source': pdf_filename})
    elif isinstance(original.metadata, dict):
        original.metadata['source'] = pdf_filename
    else:
        # ElementMetadata object
        if not hasattr(original.metadata, 'source'):
            original.metadata.source = pdf_filename
    
    retriever.vectorstore.add_documents([doc])
    retriever.docstore.mset([(doc_id, original)])

for i, summary in enumerate(table_summaries):
    doc_id = str(uuid.uuid4())
    chunk_ids.append(doc_id)

    # Extrair page_number se dispon√≠vel
    page_num = None
    if hasattr(tables[i], 'metadata') and hasattr(tables[i].metadata, 'page_number'):
        page_num = tables[i].metadata.page_number

    # Extrair section heading (tabelas geralmente t√™m context)
    section = extract_section_heading(tables[i])

    # ‚úÖ CR√çTICO: Para tabelas, usar TEXTO COMPLETO sem resumir
    # Resumos de tabelas perdem informa√ß√£o cr√≠tica (valores, crit√©rios espec√≠ficos)
    table_text = tables[i].text if hasattr(tables[i], 'text') else str(tables[i])

    # Se houver HTML da tabela, incluir tamb√©m
    table_html = ""
    if hasattr(tables[i], 'metadata') and hasattr(tables[i].metadata, 'text_as_html'):
        table_html = f"\n\n[HTML]\n{tables[i].metadata.text_as_html}"

    combined_table_content = f"{summary}\n\n[TABELA COMPLETA]\n{table_text}{table_html}"

    doc = Document(
        page_content=combined_table_content,  # ‚úÖ TABELA COMPLETA + RESUMO
        metadata={
            "doc_id": doc_id,
            "pdf_id": pdf_id,  # ‚úÖ ID do PDF
            "source": pdf_filename,
            "type": "table",
            "index": i,
            "page_number": page_num,
            "uploaded_at": uploaded_at,
            "section": section,              # ‚úÖ NOVO: Se√ß√£o do documento
            "document_type": document_type,  # ‚úÖ NOVO: Tipo de documento
            "summary": summary,               # ‚úÖ NOVO: Guardar resumo separado
        }
    )
    
    # Adicionar source √† tabela original
    original = tables[i]
    
    # Criar metadata dict se n√£o existir
    if not hasattr(original, 'metadata'):
        # Criar um objeto simples com metadata
        class DocWithMetadata:
            def __init__(self, text, metadata):
                self.text = text
                self.metadata = metadata
        original = DocWithMetadata(original.text if hasattr(original, 'text') else str(original), {'source': pdf_filename})
    elif isinstance(original.metadata, dict):
        original.metadata['source'] = pdf_filename
    else:
        # ElementMetadata object
        if not hasattr(original.metadata, 'source'):
            original.metadata.source = pdf_filename
    
    retriever.vectorstore.add_documents([doc])
    retriever.docstore.mset([(doc_id, original)])

for i, summary in enumerate(image_summaries):
    doc_id = str(uuid.uuid4())
    chunk_ids.append(doc_id)

    doc = Document(
        page_content=summary,
        metadata={
            "doc_id": doc_id,
            "pdf_id": pdf_id,  # ‚úÖ ID do PDF
            "source": pdf_filename,
            "type": "image",
            "index": i,
            "page_number": None,  # Imagens geralmente n√£o t√™m page_number
            "uploaded_at": uploaded_at,
            "section": None,                 # Imagens geralmente n√£o t√™m se√ß√£o detect√°vel
            "document_type": document_type,  # ‚úÖ NOVO: Tipo de documento
        }
    )
    
    # Imagens base64 n√£o t√™m metadata, s√≥ salvar
    retriever.vectorstore.add_documents([doc])
    retriever.docstore.mset([(doc_id, images[i])])

# Salvar
with open(docstore_path, 'wb') as f:
    pickle.dump(dict(store.store), f)

# Metadados
metadata_path = f"{persist_directory}/metadata.pkl"
metadata = {}
if os.path.exists(metadata_path):
    with open(metadata_path, 'rb') as f:
        metadata = pickle.load(f)

# Migrar estrutura antiga se necess√°rio
if 'pdfs' in metadata and 'documents' not in metadata:
    metadata['documents'] = {}
    # Converter estrutura antiga
    for old_pdf in metadata.get('pdfs', []):
        # N√£o temos pdf_id nos dados antigos, usar filename como chave tempor√°ria
        pass

if 'documents' not in metadata:
    metadata['documents'] = {}

processed_at = time.strftime("%Y-%m-%d %H:%M:%S")

# Informa√ß√µes do documento
doc_info = {
    "pdf_id": pdf_id,
    "filename": pdf_filename,
    "original_filename": os.path.basename(file_path),
    "file_size": file_size,
    "hash": pdf_id,
    "uploaded_at": uploaded_at,
    "processed_at": processed_at,
    "stats": {
        "texts": len(texts),
        "tables": len(tables),
        "images": len(images),
        "total_chunks": len(chunk_ids)
    },
    "chunk_ids": chunk_ids,
    "status": "processed",
    "error": None
}

# Atualizar ou adicionar
metadata['documents'][pdf_id] = doc_info

with open(metadata_path, 'wb') as f:
    pickle.dump(metadata, f)

print(f"   ‚úì Adicionado!\n")

# ===========================================================================
# RELAT√ìRIO DE QUALIDADE
# ===========================================================================
print("=" * 70)
print("üìä RELAT√ìRIO DE QUALIDADE DO PROCESSAMENTO")
print("=" * 70)

print(f"\nüîß Configura√ß√£o:")
print(f"   Estrat√©gia OCR: {strategy_used}")
print(f"   Idioma: Portugu√™s (por)")
print(f"   Chunking: by_title (max: 10000 chars, ~2500 tokens)")
print(f"   Combine under: 4000 chars | Soft max: 6000 chars")
print(f"   Tabelas: Sempre preservadas inteiras (isoladas)")

print(f"\nüìÑ Arquivo:")
print(f"   Nome: {pdf_filename}")
print(f"   Tamanho: {file_size / 1024 / 1024:.2f} MB")
print(f"   Tipo detectado: {document_type}")

print(f"\nüì¶ Elementos extra√≠dos:")
print(f"   Textos (CompositeElement): {len(texts)}")
print(f"   Tabelas (isoladas): {len(tables)}")
print(f"   Imagens: {len(images)}")
if filtered_count > 0:
    print(f"   (filtradas: {filtered_count} imagens pequenas <5KB)")

print(f"\nüíæ Knowledge Base:")
print(f"   PDF_ID: {pdf_id[:32]}...")
print(f"   Chunks totais: {len(chunk_ids)} ({len(texts)}T + {len(tables)}Tab + {len(images)}I)")
print(f"   Processado em: {processed_at}")

# Listar tabelas extra√≠das
if tables:
    print(f"\nüìã Tabelas encontradas ({len(tables)}):")
    for i, table in enumerate(tables):
        table_preview = table.text[:80] if hasattr(table, 'text') else str(table)[:80]
        page_num = table.metadata.page_number if hasattr(table, 'metadata') and hasattr(table.metadata, 'page_number') else '?'
        print(f"   [{i+1}] P√°gina {page_num}: {table_preview}...")

# Detectar poss√≠vel problema de OCR (muito ingl√™s em PDF portugu√™s)
all_text_content = " ".join([t.text for t in texts if hasattr(t, 'text')])
if len(all_text_content) > 100:
    # Palavras comuns em ingl√™s
    english_indicators = ['the ', ' and ', ' or ', ' with ', ' from ', ' this ', ' that ']
    english_count = sum(all_text_content.lower().count(word) for word in english_indicators)
    words_total = len(all_text_content.split())
    english_ratio = english_count / max(words_total, 1) * 100

    if english_ratio > 15:
        print(f"\n‚ö†Ô∏è  AVISO: Detectado {english_ratio:.1f}% de indicadores de ingl√™s")
        print(f"   O PDF pode ter sido mal processado.")
        print(f"   Considere verificar se o conte√∫do est√° correto.")

print("\n" + "=" * 70)

print(f"\n‚úÖ Pronto! Use:")
print(f"   - python consultar.py (terminal)")
print(f"   - /chat (web UI)")
print(f"   - /manage (gerenciar documentos)")
print()

