#!/usr/bin/env python3
"""
Script para limpar chunks Ã³rfÃ£os (filename=None) do vectorstore

Problema:
- Chunks antigos foram criados SEM campo 'filename' no metadata
- Quando documentos foram deletados, esses chunks ficaram Ã³rfÃ£os
- Resultado: chunks com filename=None ainda respondem queries

SoluÃ§Ã£o:
- Buscar TODOS os chunks do Chroma
- Identificar chunks com filename=None ou filename ausente
- Deletar esses chunks do vectorstore E docstore
- Preservar chunks vÃ¡lidos com filename preenchido
"""

import os
import pickle
from dotenv import load_dotenv

load_dotenv()

def limpar_chunks_orfaos(persist_directory: str = "./knowledge"):
    """Remove chunks Ã³rfÃ£os (sem filename) do vectorstore"""

    from langchain_chroma import Chroma
    from langchain_openai import OpenAIEmbeddings

    print("=" * 70)
    print("ğŸ§¹ LIMPEZA DE CHUNKS Ã“RFÃƒOS")
    print("=" * 70)

    # 1. Carregar vectorstore
    print("\n1ï¸âƒ£ Carregando vectorstore...")
    vectorstore = Chroma(
        collection_name="knowledge_base",
        embedding_function=OpenAIEmbeddings(model="text-embedding-3-large"),
        persist_directory=persist_directory
    )

    # 2. Buscar TODOS os chunks
    print("2ï¸âƒ£ Buscando todos os chunks...")
    all_results = vectorstore.get(include=['metadatas'])

    total_chunks = len(all_results['ids'])
    print(f"   âœ“ Total de chunks no Chroma: {total_chunks}")

    # 3. Carregar docstore para validaÃ§Ã£o profunda
    print("\n3ï¸âƒ£ Carregando docstore...")
    import pickle
    docstore_path = f"{persist_directory}/docstore.pkl"
    docstore_ids = set()

    if os.path.exists(docstore_path):
        try:
            with open(docstore_path, 'rb') as f:
                docstore = pickle.load(f)
                docstore_ids = set(docstore.keys())
                print(f"   âœ“ Docstore com {len(docstore_ids)} doc_ids vÃ¡lidos")
        except Exception as e:
            print(f"   âš ï¸  Erro ao carregar docstore: {str(e)}")
    else:
        print(f"   âš ï¸  Docstore nÃ£o encontrado em {docstore_path}")

    # 4. Identificar chunks Ã³rfÃ£os (DUAS VALIDAÃ‡Ã•ES)
    print("\n4ï¸âƒ£ Identificando chunks Ã³rfÃ£os...")
    orphan_chunk_ids = []
    valid_chunk_ids = []

    for i, meta in enumerate(all_results.get('metadatas', [])):
        chunk_id = all_results['ids'][i]
        filename = meta.get('filename')
        doc_id = meta.get('doc_id')
        source = meta.get('source', 'N/A')

        # VALIDAÃ‡ÃƒO 1: Chunk Ã³rfÃ£o = filename Ã© None, vazio, ou ausente
        orphan_reason = None
        if filename is None or filename == '' or filename == 'N/A':
            orphan_reason = "filename_missing"
        # VALIDAÃ‡ÃƒO 2: doc_id nÃ£o existe no docstore
        elif doc_id and docstore_ids and doc_id not in docstore_ids:
            orphan_reason = "doc_id_not_in_docstore"

        if orphan_reason:
            orphan_chunk_ids.append({
                'id': chunk_id,
                'source': source,
                'type': meta.get('type', 'unknown'),
                'reason': orphan_reason,
                'doc_id': doc_id
            })
        else:
            valid_chunk_ids.append(chunk_id)

    print(f"   âœ“ Chunks vÃ¡lidos (com filename): {len(valid_chunk_ids)}")
    print(f"   âš ï¸  Chunks Ã³rfÃ£os (sem filename): {len(orphan_chunk_ids)}")

    if len(orphan_chunk_ids) == 0:
        print("\nâœ… Nenhum chunk Ã³rfÃ£o encontrado! Vectorstore estÃ¡ limpo.")
        return

    # Mostrar estatÃ­sticas dos Ã³rfÃ£os
    print("\nğŸ“Š EstatÃ­sticas dos chunks Ã³rfÃ£os:")
    from collections import Counter
    orphan_sources = [c['source'] for c in orphan_chunk_ids]
    orphan_types = [c['type'] for c in orphan_chunk_ids]
    orphan_reasons = [c['reason'] for c in orphan_chunk_ids]

    source_counts = Counter(orphan_sources)
    type_counts = Counter(orphan_types)
    reason_counts = Counter(orphan_reasons)

    print("\n   Por razÃ£o:")
    for reason, count in reason_counts.most_common():
        reason_label = {
            'filename_missing': 'âŒ Sem filename',
            'doc_id_not_in_docstore': 'ğŸ”— doc_id nÃ£o existe no docstore'
        }.get(reason, reason)
        print(f"      - {reason_label}: {count} chunks")

    print("\n   Por source:")
    for source, count in source_counts.most_common():
        print(f"      - {source}: {count} chunks")

    print("\n   Por tipo:")
    for chunk_type, count in type_counts.most_common():
        print(f"      - {chunk_type}: {count} chunks")

    # 4. Confirmar deleÃ§Ã£o
    print(f"\nâš ï¸  ATENÃ‡ÃƒO: Isso vai DELETAR {len(orphan_chunk_ids)} chunks Ã³rfÃ£os!")
    print("   Chunks vÃ¡lidos serÃ£o preservados.")

    resposta = input("\nâ“ Confirma deleÃ§Ã£o? (sim/nÃ£o): ").strip().lower()

    if resposta not in ['sim', 's', 'yes', 'y']:
        print("\nâŒ OperaÃ§Ã£o cancelada pelo usuÃ¡rio.")
        return

    # 5. Deletar do vectorstore
    print("\n4ï¸âƒ£ Deletando chunks Ã³rfÃ£os do vectorstore...")
    orphan_ids_only = [c['id'] for c in orphan_chunk_ids]

    try:
        vectorstore.delete(ids=orphan_ids_only)
        print(f"   âœ“ {len(orphan_ids_only)} chunks deletados do Chroma")
    except Exception as e:
        print(f"   âœ— Erro ao deletar do Chroma: {str(e)}")
        return

    # 6. Deletar do docstore
    print("\n5ï¸âƒ£ Deletando do docstore...")
    docstore_path = f"{persist_directory}/docstore.pkl"

    if os.path.exists(docstore_path):
        try:
            with open(docstore_path, 'rb') as f:
                docstore = pickle.load(f)

            deleted_from_docstore = 0
            for chunk_id in orphan_ids_only:
                if chunk_id in docstore:
                    del docstore[chunk_id]
                    deleted_from_docstore += 1

            with open(docstore_path, 'wb') as f:
                pickle.dump(docstore, f)

            print(f"   âœ“ {deleted_from_docstore} itens deletados do docstore")

            # Atualizar timestamp para invalidar cache
            os.utime(docstore_path, None)
            print(f"   âœ“ Timestamp do docstore atualizado (invalida cache)")

        except Exception as e:
            print(f"   âš ï¸  Erro ao limpar docstore: {str(e)}")
    else:
        print(f"   â„¹ï¸  Docstore nÃ£o existe em {docstore_path}")

    # 7. Verificar resultado
    print("\n6ï¸âƒ£ Verificando resultado...")
    all_results_after = vectorstore.get(include=['metadatas'])
    total_after = len(all_results_after['ids'])

    orphans_remaining = sum(
        1 for meta in all_results_after.get('metadatas', [])
        if meta.get('filename') is None or meta.get('filename') == ''
    )

    print(f"   âœ“ Chunks antes: {total_chunks}")
    print(f"   âœ“ Chunks depois: {total_after}")
    print(f"   âœ“ Chunks deletados: {total_chunks - total_after}")
    print(f"   âœ“ Ã“rfÃ£os restantes: {orphans_remaining}")

    if orphans_remaining == 0:
        print("\nâœ… SUCESSO! Todos os chunks Ã³rfÃ£os foram removidos!")
    else:
        print(f"\nâš ï¸  Ainda hÃ¡ {orphans_remaining} chunks Ã³rfÃ£os. Execute novamente.")

    print("\n" + "=" * 70)
    print("ğŸ‰ Limpeza concluÃ­da!")
    print("=" * 70)


if __name__ == "__main__":
    import sys

    # Permitir passar persist_directory como argumento
    persist_dir = sys.argv[1] if len(sys.argv) > 1 else "./knowledge"

    print(f"\nğŸ“‚ DiretÃ³rio: {persist_dir}")

    limpar_chunks_orfaos(persist_dir)
