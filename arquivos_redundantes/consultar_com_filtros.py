#!/usr/bin/env python3
"""
Consultar Vectorstore com FILTROS AVANÃ‡ADOS
Permite filtrar por tipo, pÃ¡gina, etc usando metadados
"""

import os
import sys
from dotenv import load_dotenv
import pickle

load_dotenv()

print("=" * 80)
print("ğŸ’ CHAT COM FILTROS AVANÃ‡ADOS DE METADADOS")
print("=" * 80)
print()

if len(sys.argv) < 2:
    print("âŒ Uso: python consultar_com_filtros.py nome_do_vectorstore")
    print()
    print("Exemplo:")
    print("  python consultar_com_filtros.py Manejo_da_terapia_antidiabÃ©tica_no_DM2_metadata")
    sys.exit(1)

vectorstore_name = sys.argv[1]
persist_directory = f"./vectorstores/{vectorstore_name}"

if not os.path.exists(persist_directory):
    print(f"âŒ Vectorstore nÃ£o encontrado: {persist_directory}")
    sys.exit(1)

print(f"ğŸ“‚ Carregando vectorstore: {vectorstore_name}")
print()

# Carregar vectorstore
from langchain_chroma import Chroma
from langchain.storage import InMemoryStore
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers.multi_vector import MultiVectorRetriever

print("â³ Carregando...")

vectorstore = Chroma(
    collection_name="rag_collection",
    embedding_function=OpenAIEmbeddings(),
    persist_directory=persist_directory
)

docstore_path = f"{persist_directory}/docstore.pkl"
store = InMemoryStore()
if os.path.exists(docstore_path):
    with open(docstore_path, 'rb') as f:
        store.store = pickle.load(f)

id_key = "doc_id"

retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=store,
    id_key=id_key,
)

# Carregar metadados
metadata_path = f"{persist_directory}/metadata.pkl"
metadata = {}
if os.path.exists(metadata_path):
    with open(metadata_path, 'rb') as f:
        metadata = pickle.load(f)

print("âœ“ Vectorstore carregado!")
print()

# Mostrar informaÃ§Ãµes
if metadata:
    print("=" * 80)
    print("ğŸ“Š INFORMAÃ‡Ã•ES DO DOCUMENTO")
    print("=" * 80)
    print()
    print(f"ğŸ“„ Arquivo: {metadata.get('pdf_filename', 'N/A')}")
    print(f"ğŸ“ Textos: {metadata.get('num_texts', 0)}")
    print(f"ğŸ“Š Tabelas: {metadata.get('num_tables', 0)}")
    print(f"ğŸ–¼ï¸  Imagens: {metadata.get('num_images', 0)}")
    print(f"â° Processado: {metadata.get('processed_at', 'N/A')}")
    
    if 'metadata_fields' in metadata:
        print(f"\nğŸ’ Metadados disponÃ­veis:")
        for field in metadata['metadata_fields']:
            print(f"  â€¢ {field}")
    print()

# ============================================================================
# CONFIGURAR PIPELINE RAG
# ============================================================================
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from base64 import b64decode

def parse_docs(docs):
    b64 = []
    text = []
    for doc in docs:
        try:
            b64decode(doc)
            b64.append(doc)
        except:
            text.append(doc)
    return {"images": b64, "texts": text}

def build_prompt(kwargs):
    docs_by_type = kwargs["context"]
    user_question = kwargs["question"]
    
    context_text = ""
    if len(docs_by_type["texts"]) > 0:
        for text_element in docs_by_type["texts"]:
            context_text += text_element.text
    
    prompt_template = f"""
    Answer the question based on the following context.
    Context: {context_text}
    Question: {user_question}
    """
    
    prompt_content = [{"type": "text", "text": prompt_template}]
    
    if len(docs_by_type["images"]) > 0:
        for image in docs_by_type["images"]:
            prompt_content.append({
                "type": "image_url",
                "image_url": {"url": f"data:image/jpeg;base64,{image}"},
            })
    
    return ChatPromptTemplate.from_messages([HumanMessage(content=prompt_content)])

chain_with_sources = {
    "context": retriever | RunnableLambda(parse_docs),
    "question": RunnablePassthrough(),
} | RunnablePassthrough().assign(
    response=(
        RunnableLambda(build_prompt)
        | ChatOpenAI(model="gpt-4o-mini")
        | StrOutputParser()
    )
)

# ============================================================================
# CHAT INTERATIVO COM FILTROS
# ============================================================================
print("=" * 80)
print("âœ… SISTEMA COM METADADOS AVANÃ‡ADOS PRONTO!")
print("=" * 80)
print()
print("ğŸ’¡ Comandos disponÃ­veis:")
print("  â€¢ Digite sua pergunta normalmente")
print("  â€¢ 'info' â†’ Ver estatÃ­sticas e metadados")
print("  â€¢ 'filtrar:tipo' â†’ Filtrar por tipo (texto/tabela/imagem)")
print("  â€¢ 'filtrar:pagina:N' â†’ Filtrar por pÃ¡gina N")
print("  â€¢ 'meta' â†’ Ver metadados das Ãºltimas fontes")
print("  â€¢ 'sair' â†’ Encerrar")
print()

conversation_count = 0
last_response = None

while True:
    try:
        print("â”€" * 80)
        question = input("\nğŸ¤” Sua pergunta: ").strip()
        
        if not question:
            continue
        
        # Comandos especiais
        if question.lower() in ['sair', 'exit', 'quit', 'q']:
            print("\nğŸ‘‹ Encerrando chat. AtÃ© logo!")
            break
        
        if question.lower() == 'info':
            print(f"\nğŸ“Š InformaÃ§Ãµes:")
            if metadata:
                print(f"  â€¢ Arquivo: {metadata.get('pdf_filename', 'N/A')}")
                print(f"  â€¢ Textos: {metadata.get('num_texts', 0)}")
                print(f"  â€¢ Tabelas: {metadata.get('num_tables', 0)}")
                print(f"  â€¢ Imagens: {metadata.get('num_images', 0)}")
                print(f"  â€¢ Perguntas feitas: {conversation_count}")
                if 'metadata_fields' in metadata:
                    print(f"\n  ğŸ’ Campos de metadados disponÃ­veis:")
                    for field in metadata['metadata_fields']:
                        print(f"    â€¢ {field}")
            continue
        
        if question.lower() == 'meta' and last_response:
            print("\nğŸ’ Metadados das Ãºltimas fontes consultadas:")
            print("-" * 80)
            for i, text in enumerate(last_response['context']['texts'][:3]):
                if hasattr(text, 'metadata'):
                    print(f"\nFonte {i+1}:")
                    meta = text.metadata if isinstance(text.metadata, dict) else {}
                    for key, value in meta.items():
                        if key != 'orig_elements':  # NÃ£o mostrar elementos internos
                            print(f"  â€¢ {key}: {value}")
            continue
        
        # Filtros avanÃ§ados
        search_filter = None
        if question.lower().startswith('filtrar:'):
            parts = question.split(':')
            if len(parts) == 2:
                filter_type = parts[1]
                if filter_type in ['texto', 'text', 'tabela', 'table', 'imagem', 'image']:
                    content_type_map = {
                        'texto': 'text', 'text': 'text',
                        'tabela': 'table', 'table': 'table',
                        'imagem': 'image', 'image': 'image'
                    }
                    search_filter = {"content_type": content_type_map[filter_type]}
                    print(f"\nğŸ” Filtrando por: {content_type_map[filter_type]}")
                    question = input("Digite sua pergunta: ").strip()
            elif len(parts) == 3 and parts[1] == 'pagina':
                try:
                    page_num = int(parts[2])
                    search_filter = {"page_number": page_num}
                    print(f"\nğŸ” Filtrando por pÃ¡gina: {page_num}")
                    question = input("Digite sua pergunta: ").strip()
                except:
                    print("âŒ NÃºmero de pÃ¡gina invÃ¡lido")
                    continue
        
        if not question:
            continue
        
        # Processar pergunta
        print("\nâ³ Buscando resposta...")
        
        # Se tem filtro, fazer busca filtrada
        if search_filter:
            # Busca com filtro de metadados
            docs_filtered = vectorstore.similarity_search(
                question,
                k=4,
                filter=search_filter
            )
            print(f"   Encontrados {len(docs_filtered)} documentos com filtro")
        
        response = chain_with_sources.invoke(question)
        last_response = response
        
        conversation_count += 1
        
        # Mostrar resposta
        print("\nğŸ¤– Resposta:")
        print("-" * 80)
        print(response['response'])
        print("-" * 80)
        
        # Mostrar fontes com metadados
        num_texts = len(response['context']['texts'])
        num_images = len(response['context']['images'])
        print(f"\nğŸ“š Fontes consultadas: {num_texts} textos, {num_images} imagens")
        
        # Mostrar pÃ¡ginas consultadas
        pages = set()
        for text in response['context']['texts']:
            if hasattr(text, 'metadata'):
                meta = text.metadata if isinstance(text.metadata, dict) else {}
                if 'page_number' in meta:
                    pages.add(meta['page_number'])
        
        if pages:
            print(f"ğŸ“„ PÃ¡ginas consultadas: {sorted(pages)}")
        
        print(f"\nğŸ’¡ Digite 'meta' para ver detalhes dos metadados das fontes")
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Encerrando chat. AtÃ© logo!")
        break
    except Exception as e:
        print(f"\nâŒ Erro: {str(e)[:100]}")
        print("Tente outra pergunta.")

print()
print("=" * 80)
print(f"SessÃ£o encerrada. Total de perguntas: {conversation_count}")
print("=" * 80)

