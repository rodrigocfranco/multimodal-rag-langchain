# ğŸ”§ SoluÃ§Ãµes Implementadas para Melhorar Respostas da IA

## ğŸ“Š Resumo do Problema

**Taxa de sucesso original:** 3/6 perguntas (50%)

**Perguntas que falharam:**
1. âŒ "Qual a relaÃ§Ã£o entre albuminÃºria e risco cardiovascular?"
2. âŒ "Em quais situaÃ§Ãµes a diretriz recomenda NÃƒO usar insulina como primeira linha?"
3. âŒ "Existem situaÃ§Ãµes onde glicose em jejum normal NÃƒO descarta diabetes?"

---

## ğŸ¯ Root Causes Identificadas

### Causa 1: Prompt Extremamente Restritivo
O prompt original proibia **qualquer inferÃªncia lÃ³gica**, mesmo quando a informaÃ§Ã£o estava presente em mÃºltiplos chunks:

```python
"1. Responda APENAS com informaÃ§Ãµes que estÃ£o EXPLICITAMENTE no contexto"
```

**Problema:** Perguntas sobre "relaÃ§Ã£o", negaÃ§Ãµes ("NÃƒO usar"), e duplas negaÃ§Ãµes ("NÃƒO descarta") exigem conectar informaÃ§Ãµes dispersas.

### Causa 2: Embeddings Fracos com NegaÃ§Ãµes/AbstraÃ§Ãµes
- OpenAI embeddings (`text-embedding-3-large`) tÃªm dificuldade com:
  - âŒ NegaÃ§Ãµes: "quando **NÃƒO** usar"
  - âŒ AbstraÃ§Ãµes: "**relaÃ§Ã£o** entre X e Y"
  - âŒ Dupla negaÃ§Ã£o: "**NÃƒO descarta**"

### Causa 3: top_n=8 Insuficiente para Perguntas Complexas
- Reranker retornava apenas os **top 8** chunks
- Perguntas abstratas podem precisar de **10-12 chunks** para encontrar todas as informaÃ§Ãµes relevantes

---

## âœ… SoluÃ§Ãµes Implementadas

### SoluÃ§Ã£o 1: Novo Prompt com "InferÃªncia Moderada Guiada" ğŸ”¥

**Arquivo:** `consultar_com_rerank.py` (linhas 171-187 e 891-908)

**MudanÃ§as:**

```python
# âŒ ANTES (muito restritivo)
"""
REGRAS CRÃTICAS:
1. Responda APENAS com informaÃ§Ãµes que estÃ£o EXPLICITAMENTE no contexto
2. Se NÃƒO estiver no contexto, responda: "A informaÃ§Ã£o nÃ£o estÃ¡ presente"
3. NUNCA use conhecimento externo
"""

# âœ… DEPOIS (permite inferÃªncia lÃ³gica documentada)
"""
REGRAS CRÃTICAS:
1. Responda APENAS com informaÃ§Ãµes que estÃ£o no contexto fornecido
2. NUNCA use conhecimento geral ou externo aos documentos
3. Cite EXATAMENTE como estÃ¡ escrito no documento

INFERÃŠNCIAS PERMITIDAS (apenas quando necessÃ¡rio):
6. Se a pergunta pede "relaÃ§Ã£o entre X e Y", vocÃª PODE conectar informaÃ§Ãµes de
   DIFERENTES trechos do contexto, citando AMBOS
7. Se a pergunta pede "quando NÃƒO fazer X" e o contexto diz "fazer Y em situaÃ§Ã£o Z",
   vocÃª PODE inferir logicamente, citando o trecho original
8. Se a pergunta usa negaÃ§Ã£o ("NÃƒO descarta", "NÃƒO Ã© recomendado"), procure
   informaÃ§Ãµes complementares no contexto que respondam indiretamente

REGRA FINAL:
9. Se apÃ³s tentar conexÃµes lÃ³gicas a informaÃ§Ã£o AINDA nÃ£o puder ser inferida do
   contexto, responda: "A informaÃ§Ã£o solicitada nÃ£o estÃ¡ presente nos documentos"
"""
```

**Por que isso ajuda:**
- âœ… Permite conectar "critÃ©rios de risco" + "marcador de lesÃ£o endotelial" â†’ "relaÃ§Ã£o entre albuminÃºria e risco CV"
- âœ… Permite inferir "NÃƒO usar insulina" a partir de "usar iSGLT2 quando HbA1c < 7,5%"
- âœ… MantÃ©m rigor: exige citaÃ§Ã£o dos trechos usados
- âœ… Anti-alucinaÃ§Ã£o: se nÃ£o houver base lÃ³gica, ainda responde "informaÃ§Ã£o nÃ£o presente"

---

### SoluÃ§Ã£o 2: Aumentar top_n (8 â†’ 10) ğŸ“ˆ

**Arquivo:** `consultar_com_rerank.py` (linhas 108-111 e 806-809)

```python
# âŒ ANTES
compressor = CohereRerank(
    model="rerank-multilingual-v3.0",
    top_n=8  # Apenas 8 documentos
)

# âœ… DEPOIS
compressor = CohereRerank(
    model="rerank-multilingual-v3.0",
    top_n=10  # 25% mais contexto
)
```

**Por que isso ajuda:**
- âœ… Mais chunks chegam ao LLM (10 vs 8 = +25% de contexto)
- âœ… Maior probabilidade de incluir chunk com "explicaÃ§Ã£o" da relaÃ§Ã£o
- âœ… Cohere Ã© rÃ¡pido, nÃ£o impacta muito a latÃªncia

**Trade-offs:**
- âš ï¸ Custo Cohere aumenta ~25% (mas ainda barato: ~$1/1000 queries)
- âš ï¸ Token count do LLM aumenta ~25% (GPT-4o-mini Ã© barato: ~$0.15/1M tokens)
- âœ… Impacto na latÃªncia: ~100-150ms adicionais (aceitÃ¡vel)

---

### SoluÃ§Ã£o 3: Aumentar k do Base Retriever (20 â†’ 25) ğŸ”

**Arquivo:** `consultar_com_rerank.py` (linhas 63-68 e 760-765)

```python
# âŒ ANTES
base_retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=store,
    id_key="doc_id",
    search_kwargs={"k": 20}
)

# âœ… DEPOIS
base_retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=store,
    id_key="doc_id",
    search_kwargs={"k": 25}  # +25% de chunks para reranking
)
```

**Por que isso ajuda:**
- âœ… Mais diversidade de chunks antes do reranking
- âœ… Compensa embeddings fracos com negaÃ§Ãµes (busca inicial pega mais variaÃ§Ãµes)
- âœ… ChromaDB nÃ£o tem indexaÃ§Ã£o HNSW no Railway, entÃ£o k maior ajuda na cobertura

---

## ğŸ§ª Como Testar as Melhorias

### Teste 1: Perguntas que Falharam Originalmente

**Refazer as 3 perguntas problemÃ¡ticas:**

```bash
# Iniciar servidor
python consultar_com_rerank.py --api

# Em outro terminal, testar:
curl -X POST http://localhost:5001/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Qual a relaÃ§Ã£o entre albuminÃºria e risco cardiovascular segundo a diretriz brasileira de diabetes 2025?"}'

curl -X POST http://localhost:5001/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Em quais situaÃ§Ãµes a diretriz recomenda NÃƒO usar insulina como primeira linha no DM2?"}'

curl -X POST http://localhost:5001/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Existem situaÃ§Ãµes onde glicose em jejum normal NÃƒO descarta diabetes?"}'
```

**CritÃ©rio de sucesso:**
- âœ… **Ideal:** Respostas substantivas citando trechos do documento
- âš ï¸ **AceitÃ¡vel:** Resposta parcial com citaÃ§Ã£o correta
- âŒ **Falha:** "A informaÃ§Ã£o nÃ£o estÃ¡ presente nos documentos"

---

### Teste 2: Verificar que Perguntas Boas NÃƒO Pioraram

**Refazer as 3 perguntas que funcionavam:**

```bash
# Q2: ContraindicaÃ§Ãµes da metformina
curl -X POST http://localhost:5001/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Quais sÃ£o as contraindicaÃ§Ãµes absolutas e relativas da metformina mencionadas no documento?"}'

# Q5: Valor exato de TFG
curl -X POST http://localhost:5001/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Qual o valor EXATO de TFG que define risco cardiovascular muito alto segundo a diretriz?"}'

# Q6: Valores de HbA1c
curl -X POST http://localhost:5001/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Liste TODOS os valores de HbA1c mencionados no documento e seus respectivos contextos de uso"}'
```

**CritÃ©rio de sucesso:**
- âœ… Respostas devem ser **tÃ£o boas ou melhores** que antes
- âŒ Se pioraram, pode indicar que top_n=10 estÃ¡ trazendo ruÃ­do

---

### Teste 3: Debug do Retrieval

**Verificar QUANTOS chunks estÃ£o sendo retornados:**

```bash
curl -X POST http://localhost:5001/debug-retrieval \
  -H "Content-Type: application/json" \
  -d '{"question": "Qual a relaÃ§Ã£o entre albuminÃºria e risco cardiovascular?"}'
```

**O que analisar:**
- `raw_retrieval.count`: Deve ser **~25** (k=25)
- `reranked.count`: Deve ser **10** (top_n=10)
- `reranked.docs[].content_preview`: Verificar se hÃ¡ chunks sobre "albuminÃºria" + "risco CV" + "critÃ©rios" + "marcador"

---

## ğŸ“Š Resultados Esperados

### CenÃ¡rio Ideal (90-100% de sucesso)
| Pergunta | Status Antes | Status Esperado Depois |
|----------|-------------|------------------------|
| Q1: RelaÃ§Ã£o albuminÃºria e risco CV | âŒ | âœ… |
| Q2: ContraindicaÃ§Ãµes metformina | âœ… | âœ… |
| Q3: Quando NÃƒO usar insulina | âŒ | âœ… |
| Q4: Glicose normal NÃƒO descarta DM | âŒ | âœ… |
| Q5: Valor exato TFG | âœ… | âœ… |
| Q6: Valores HbA1c | âœ… | âœ… |
| **Taxa de sucesso** | **50%** | **100%** |

### CenÃ¡rio Realista (70-85% de sucesso)
- Q1 e Q4 resolvidas (prompt de inferÃªncia ajuda)
- Q3 ainda pode falhar (negaÃ§Ã£o muito complexa)
- **Taxa de sucesso esperada: 5/6 (83%)**

### CenÃ¡rio MÃ­nimo AceitÃ¡vel (67% de sucesso)
- Pelo menos 1 das 3 falhas foi resolvida
- Nenhuma das 3 perguntas boas piorou
- **Taxa de sucesso: 4/6 (67%)**

---

## ğŸš¨ Rollback (se necessÃ¡rio)

Se as mudanÃ§as **piorarem** o desempenho geral:

### Reverter SoluÃ§Ã£o 1 (Prompt):
```bash
git diff HEAD~1 consultar_com_rerank.py | grep "system_instruction"
# Copiar prompt antigo de volta
```

### Reverter SoluÃ§Ãµes 2 e 3 (top_n e k):
```python
# Voltar para:
top_n=8  # Era 10
search_kwargs={"k": 20}  # Era 25
```

---

## ğŸ¯ PrÃ³ximos Passos Caso as SoluÃ§Ãµes NÃ£o Funcionem

### SoluÃ§Ã£o AvanÃ§ada 1: Query Expansion
Se Q1 e Q3 ainda falharem, implementar **expansÃ£o de query**:
- Usar GPT-4o-mini para gerar 3 reformulaÃ§Ãµes da pergunta
- Buscar com todas as variaÃ§Ãµes
- Rerank todos os resultados
- **Custo:** +$0.001 por query
- **LatÃªncia:** +300-500ms

### SoluÃ§Ã£o AvanÃ§ada 2: Hybrid Search (BM25 + Embeddings)
Para negaÃ§Ãµes e termos exatos:
- Adicionar BM25 (busca lexical) ao lado dos embeddings
- Combinar resultados com Reciprocal Rank Fusion
- **Complexidade:** Alta
- **Ganho esperado:** +10-15% de precisÃ£o

### SoluÃ§Ã£o AvanÃ§ada 3: Chunking SemÃ¢ntico Melhorado
Re-processar PDFs com:
- Chunks maiores (1500 tokens vs 1000)
- Overlap maior (200 tokens vs 100)
- **Custo:** Reprocessar todos os PDFs
- **Ganho esperado:** +5-10% de recall

---

## ğŸ“ˆ MÃ©tricas de Sucesso

**Imediato (apÃ³s deploy):**
- [ ] Taxa de sucesso â‰¥ 67% (4/6 perguntas)
- [ ] LatÃªncia mÃ©dia < 3 segundos
- [ ] Custo por query < $0.01

**MÃ©dio prazo (1 semana de uso):**
- [ ] Taxa de satisfaÃ§Ã£o do usuÃ¡rio â‰¥ 80%
- [ ] Taxa de "informaÃ§Ã£o nÃ£o presente" < 20%
- [ ] Tempo mÃ©dio de resposta < 2.5 segundos

**Longo prazo (1 mÃªs):**
- [ ] Taxa de sucesso â‰¥ 90% em perguntas complexas
- [ ] Zero alucinaÃ§Ãµes detectadas
- [ ] Custo operacional < $50/mÃªs

---

## ğŸ” Comandos Ãšteis para Monitoramento

### Ver logs em produÃ§Ã£o (Railway)
```bash
railway logs --follow
```

### Testar localmente
```bash
python consultar_com_rerank.py --api
# Abrir http://localhost:5001/chat
```

### Comparar performance antes/depois
```bash
# Salvar respostas antigas
curl ... > respostas_antes.json

# Salvar respostas novas
curl ... > respostas_depois.json

# Comparar
diff respostas_antes.json respostas_depois.json
```

---

**Data de implementaÃ§Ã£o:** 2025-10-17
**VersÃ£o do cÃ³digo:** consultar_com_rerank.py (commit atual)
**Status:** âœ… Implementado, aguardando testes
